
# Week 1

TODO Implement Skip Gram with Negative Sampling
See chat with ChatGPT, title "SkipGram Dataset Recommendations"
https://chatgpt.com/share/68587e02-d470-8002-9aa3-7b8e1af4732b

Other locations of HackerNews dataset:
- https://paperswithcode.com/dataset/hacker-news
- TBD

Word2Vec embeddings:
- Negative sampling, hierarchical softmax, skip gram
- Tests as others were performing for word2vec embeddings
- Implement training word2vec using numpy (probably choose a smaller dataset for this)
- Use official Wikipedia datasets as input
- Evaluate the effect of increasing dimensions
- Doc2Vec model

Use GPU monitoring in command line when running

